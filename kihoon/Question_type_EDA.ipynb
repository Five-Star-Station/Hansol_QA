{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "toc_visible": true,
      "authorship_tag": "ABX9TyPya7G0wT+74NE66jHNMFRG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Five-Star-Station/Hansol_QA/blob/main/kihoon/Question_type_EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zIzYDOCQs78o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-L2I3lFeOQ6",
        "outputId": "5b03d982-1e65-4be1-8a26-999a7684c4e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/280.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m256.0/280.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.27.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "POi93pDLeBJP",
        "outputId": "2fecca1c-4b1e-42a0-d9b9-5712552fc216"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-27bb0fce5fe1>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;34m'beomi/llama-2-ko-7b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;34m'beomi/llama-2-ko-7b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mpad_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    567\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3235\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mContextManagers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_contexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m         \u001b[0;31m# make sure we use the model's config since the __init__ call might have copied it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLlamaModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLlamaDecoderLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLlamaRMSNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrms_norm_eps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, _freeze, device, dtype)\u001b[0m\n\u001b[1;32m    142\u001b[0m             self.weight = Parameter(torch.empty((num_embeddings, embedding_dim), **factory_kwargs),\n\u001b[1;32m    143\u001b[0m                                     requires_grad=not _freeze)\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mreset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fill_padding_idx_with_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/init.py\u001b[0m in \u001b[0;36mnormal_\u001b[0;34m(tensor, mean, std)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_no_grad_normal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m def trunc_normal_(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/init.py\u001b[0m in \u001b[0;36m_no_grad_normal_\u001b[0;34m(tensor, mean, std)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_no_grad_normal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "  'beomi/llama-2-ko-7b'\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "  'beomi/llama-2-ko-7b',\n",
        "  pad_token_id=tokenizer.eos_token_id,\n",
        "  torch_dtype='auto'\n",
        ").to(device='cuda', non_blocking=True)\n",
        "_ = model.eval()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def generate_text(input_text):\n",
        "  prompt = f\"\"\"\n",
        "  your role is text classifier. you are a helpful assistant. you should classify the input text into one of the following categories : [0, 1, 2, 3, 4, 5].\n",
        "\n",
        "  ###\n",
        "  instruction :\n",
        "  types of the text are 5. The texts are question statements\n",
        "  0 - questions about the specific concepts,\n",
        "  1 - questions about strength and weakness of a specific product,\n",
        "  2 - questions about kinds of the product,\n",
        "  3 - requesting to get recommendation about products,\n",
        "  4 - questions about the solution of specific problem.\n",
        "\n",
        "  examples of types :\n",
        "  exapmles of questions for the types\n",
        "  0 type - [\"면진구조가 뭐야?\", \"폴리싱 타입이 뭐야?\"]\n",
        "  1 type - [\"철골 구조의 장점이 뭐야?\", \"포세린 타일의 단점이 뭐야?\"]\n",
        "  2 type - [\"화재 관련 마감재 종류가 뭐가 있어?\", \"내진 설계의 종류 좀 알려줘\"]\n",
        "  3 type - [\"방수 마갑재로 가장 널리 쓰이는 것은 뭐야?\"]\n",
        "  4 type - [\"겨울철 결로 방지를 하기 위해선 무엇을 해야해?\"]\n",
        "\n",
        "  expecations :\n",
        "\n",
        "  (1) question : 면진구조가 뭐야? / answer : 0\n",
        "  (2) question : 큐블럭의 단점이 뭐야? / answer : 1\n",
        "  (3) question : 도배풀의 종류 좀 알려줘 / answer : 2\n",
        "  (4) question : 벽지와 도료 중 어떤 것을 선택해야 하나요? / answer : 3\n",
        "  (5) question : 반점이 생긴지 1년 이내인 하자는 보수작업은 어떻게 해? / answer : 4\n",
        "\n",
        "  ###<ctrl63>\n",
        "\n",
        "  input :\n",
        "  {input_text}\n",
        "\n",
        "  output :\n",
        "  ###\n",
        "  \"\"\"\n",
        "  with torch.no_grad():\n",
        "    tokens = tokenizer.encode(prompt, return_tensors='pt').to(device='cuda', non_blocking=True)\n",
        "    gen_tokens = model.generate(tokens, do_sample=True, temperature=0.8, max_new_tokens=1)\n",
        "    generated = tokenizer.batch_decode(gen_tokens)[0]\n",
        "\n",
        "  print(generated)\n"
      ],
      "metadata": {
        "id": "4EquLE7bu89y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "m4__PF3eu8sM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\"\\\"광명단 페인트가 뭐야?\\\"\" )\n",
        "\n",
        "# 위의 프롬프트를 주었을 떄 챗 지피티는 정확하게 분류하는 것을 확인할 수 있었습니다.\n",
        "# 프롬프트가 너무 길어서 문제였을 수 있습니다.\n",
        "# 프롬프트를 한국어로 줬을 때는 답변이 매우 부정확했지만, 영어로 주니까 비교적 의도대로 하는 것을 확인했습니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHXj1uiEhoz1",
        "outputId": "1ea0621e-a25d-45c4-b73a-7d245ca029ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "  your role is text classifier. you are a helpful assistant. you should classify the input text into one of the following categories : [0, 1, 2, 3, 4, 5].\n",
            "\n",
            "  ###\n",
            "  instruction :\n",
            "  types of the text are 5. The texts are question statements\n",
            "  0 - questions about the specific concepts,\n",
            "  1 - questions about strength and weakness of a specific product,\n",
            "  2 - questions about kinds of the product,\n",
            "  3 - requesting to get recommendation about products,\n",
            "  4 - questions about the solution of specific problem. \n",
            "\n",
            "  examples of types :\n",
            "  exapmles of questions for the types\n",
            "  0 type - [\"면진구조가 뭐야?\", \"폴리싱 타입이 뭐야?\"]\n",
            "  1 type - [\"철골 구조의 장점이 뭐야?\", \"포세린 타일의 단점이 뭐야?\"]\n",
            "  2 type - [\"화재 관련 마감재 종류가 뭐가 있어?\", \"내진 설계의 종류 좀 알려줘\"]\n",
            "  3 type - [\"방수 마갑재로 가장 널리 쓰이는 것은 뭐야?\"]\n",
            "  4 type - [\"겨울철 결로 방지를 하기 위해선 무엇을 해야해?\"]\n",
            "\n",
            "  expecations :\n",
            "\n",
            "  (1) question : 면진구조가 뭐야? / answer : 0\n",
            "  (2) question : 큐블럭의 단점이 뭐야? / answer : 1\n",
            "  (3) question : 도배풀의 종류 좀 알려줘 / answer : 2\n",
            "  (4) question : 벽지와 도료 중 어떤 것을 선택해야 하나요? / answer : 3\n",
            "  (5) question : 반점이 생긴지 1년 이내인 하자는 보수작업은 어떻게 해? / answer : 4\n",
            "\n",
            "  ###<ctrl63>\n",
            "\n",
            "  input :\n",
            "  \"광명단 페인트가 뭐야?\"\n",
            "\n",
            "  output :\n",
            "  ###\n",
            "  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\"\\\"밀풀에 대해 알려줘\\\"\")"
      ],
      "metadata": {
        "id": "CH3mpu6Uhr63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25fcbab0-95e8-4aec-cc8b-6d2c3b25d1d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "  your role is text classifier. you are a helpful assistant. you should classify the input text into one of the following categories : [0, 1, 2, 3, 4, 5].\n",
            "\n",
            "  ###\n",
            "  instruction :\n",
            "  types of the text are 5. The texts are question statements\n",
            "  0 - questions about the specific concepts,\n",
            "  1 - questions about strength and weakness of a specific product,\n",
            "  2 - questions about kinds of the product,\n",
            "  3 - requesting to get recommendation about products,\n",
            "  4 - questions about the solution of specific problem. \n",
            "\n",
            "  examples of types :\n",
            "  exapmles of questions for the types\n",
            "  0 type - [\"면진구조가 뭐야?\", \"폴리싱 타입이 뭐야?\"]\n",
            "  1 type - [\"철골 구조의 장점이 뭐야?\", \"포세린 타일의 단점이 뭐야?\"]\n",
            "  2 type - [\"화재 관련 마감재 종류가 뭐가 있어?\", \"내진 설계의 종류 좀 알려줘\"]\n",
            "  3 type - [\"방수 마갑재로 가장 널리 쓰이는 것은 뭐야?\"]\n",
            "  4 type - [\"겨울철 결로 방지를 하기 위해선 무엇을 해야해?\"]\n",
            "\n",
            "  expecations :\n",
            "\n",
            "  (1) question : 면진구조가 뭐야? / answer : 0\n",
            "  (2) question : 큐블럭의 단점이 뭐야? / answer : 1\n",
            "  (3) question : 도배풀의 종류 좀 알려줘 / answer : 2\n",
            "  (4) question : 벽지와 도료 중 어떤 것을 선택해야 하나요? / answer : 3\n",
            "  (5) question : 반점이 생긴지 1년 이내인 하자는 보수작업은 어떻게 해? / answer : 4\n",
            "\n",
            "  ###<ctrl63>\n",
            "\n",
            "  input :\n",
            "  \"밀풀에 대해 알려줘\"\n",
            "\n",
            "  output :\n",
            "  ###\n",
            "  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\"\\\"포세린 타일의 단점이 뭐야?\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTxkb70U17hm",
        "outputId": "5b475ecd-87c3-4963-b58f-5cf3682fe62a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "  your role is text classifier. you are a helpful assistant. you should classify the input text into one of the following categories : [0, 1, 2, 3, 4, 5].\n",
            "\n",
            "  ###\n",
            "  instruction :\n",
            "  types of the text are 5. The texts are question statements\n",
            "  0 - questions about the specific concepts,\n",
            "  1 - questions about strength and weakness of a specific product,\n",
            "  2 - questions about kinds of the product,\n",
            "  3 - requesting to get recommendation about products,\n",
            "  4 - questions about the solution of specific problem. \n",
            "\n",
            "  examples of types :\n",
            "  exapmles of questions for the types\n",
            "  0 type - [\"면진구조가 뭐야?\", \"폴리싱 타입이 뭐야?\"]\n",
            "  1 type - [\"철골 구조의 장점이 뭐야?\", \"포세린 타일의 단점이 뭐야?\"]\n",
            "  2 type - [\"화재 관련 마감재 종류가 뭐가 있어?\", \"내진 설계의 종류 좀 알려줘\"]\n",
            "  3 type - [\"방수 마갑재로 가장 널리 쓰이는 것은 뭐야?\"]\n",
            "  4 type - [\"겨울철 결로 방지를 하기 위해선 무엇을 해야해?\"]\n",
            "\n",
            "  expecations :\n",
            "\n",
            "  (1) question : 면진구조가 뭐야? / answer : 0\n",
            "  (2) question : 큐블럭의 단점이 뭐야? / answer : 1\n",
            "  (3) question : 도배풀의 종류 좀 알려줘 / answer : 2\n",
            "  (4) question : 벽지와 도료 중 어떤 것을 선택해야 하나요? / answer : 3\n",
            "  (5) question : 반점이 생긴지 1년 이내인 하자는 보수작업은 어떻게 해? / answer : 4\n",
            "\n",
            "  ###<ctrl63>\n",
            "\n",
            "  input :\n",
            "  \"포세린 타일의 단점이 뭐야?\"\n",
            "\n",
            "  output :\n",
            "  ###\n",
            "  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\"\\\"점토기와의 장점은 뭐야?\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3dWgzDJ3ALE",
        "outputId": "854f6a79-185b-4af9-9345-0f4530a2cc7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "  your role is text classifier. you are a helpful assistant. you should classify the input text into one of the following categories : [0, 1, 2, 3, 4, 5].\n",
            "\n",
            "  ###\n",
            "  instruction :\n",
            "  types of the text are 5. The texts are question statements\n",
            "  0 - questions about the specific concepts,\n",
            "  1 - questions about strength and weakness of a specific product,\n",
            "  2 - questions about kinds of the product,\n",
            "  3 - requesting to get recommendation about products,\n",
            "  4 - questions about the solution of specific problem. \n",
            "\n",
            "  examples of types :\n",
            "  exapmles of questions for the types\n",
            "  0 type - [\"면진구조가 뭐야?\", \"폴리싱 타입이 뭐야?\"]\n",
            "  1 type - [\"철골 구조의 장점이 뭐야?\", \"포세린 타일의 단점이 뭐야?\"]\n",
            "  2 type - [\"화재 관련 마감재 종류가 뭐가 있어?\", \"내진 설계의 종류 좀 알려줘\"]\n",
            "  3 type - [\"방수 마갑재로 가장 널리 쓰이는 것은 뭐야?\"]\n",
            "  4 type - [\"겨울철 결로 방지를 하기 위해선 무엇을 해야해?\"]\n",
            "\n",
            "  expecations :\n",
            "\n",
            "  (1) question : 면진구조가 뭐야? / answer : 0\n",
            "  (2) question : 큐블럭의 단점이 뭐야? / answer : 1\n",
            "  (3) question : 도배풀의 종류 좀 알려줘 / answer : 2\n",
            "  (4) question : 벽지와 도료 중 어떤 것을 선택해야 하나요? / answer : 3\n",
            "  (5) question : 반점이 생긴지 1년 이내인 하자는 보수작업은 어떻게 해? / answer : 4\n",
            "\n",
            "  ###<ctrl63>\n",
            "\n",
            "  input :\n",
            "  \"점토기와의 장점은 뭐야?\"\n",
            "\n",
            "  output :\n",
            "  ###\n",
            "  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\"\\\"데코타일의 장점이 뭐야?\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3hMMqkG4EiD",
        "outputId": "472f7f96-bb39-4b61-c4da-82b95d02eb2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "  your role is text classifier. you are a helpful assistant. you should classify the input text into one of the following categories : [0, 1, 2, 3, 4, 5].\n",
            "\n",
            "  ###\n",
            "  instruction :\n",
            "  types of the text are 5. The texts are question statements\n",
            "  0 - questions about the specific concepts,\n",
            "  1 - questions about strength and weakness of a specific product,\n",
            "  2 - questions about kinds of the product,\n",
            "  3 - requesting to get recommendation about products,\n",
            "  4 - questions about the solution of specific problem. \n",
            "\n",
            "  examples of types :\n",
            "  exapmles of questions for the types\n",
            "  0 type - [\"면진구조가 뭐야?\", \"폴리싱 타입이 뭐야?\"]\n",
            "  1 type - [\"철골 구조의 장점이 뭐야?\", \"포세린 타일의 단점이 뭐야?\"]\n",
            "  2 type - [\"화재 관련 마감재 종류가 뭐가 있어?\", \"내진 설계의 종류 좀 알려줘\"]\n",
            "  3 type - [\"방수 마갑재로 가장 널리 쓰이는 것은 뭐야?\"]\n",
            "  4 type - [\"겨울철 결로 방지를 하기 위해선 무엇을 해야해?\"]\n",
            "\n",
            "  expecations :\n",
            "\n",
            "  (1) question : 면진구조가 뭐야? / answer : 0\n",
            "  (2) question : 큐블럭의 단점이 뭐야? / answer : 1\n",
            "  (3) question : 도배풀의 종류 좀 알려줘 / answer : 2\n",
            "  (4) question : 벽지와 도료 중 어떤 것을 선택해야 하나요? / answer : 3\n",
            "  (5) question : 반점이 생긴지 1년 이내인 하자는 보수작업은 어떻게 해? / answer : 4\n",
            "\n",
            "  ###<ctrl63>\n",
            "\n",
            "  input :\n",
            "  \"데코타일의 장점이 뭐야?\"\n",
            "\n",
            "  output :\n",
            "  ###\n",
            "  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\"\\\"차음재 종류는 뭐가 있어?\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyqiQhDi4Zhc",
        "outputId": "7c9c940b-99c1-4ed6-d9ed-e6726699c8a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "  your role is text classifier. you are a helpful assistant. you should classify the input text into one of the following categories : [0, 1, 2, 3, 4, 5].\n",
            "\n",
            "  ###\n",
            "  instruction :\n",
            "  types of the text are 5. The texts are question statements\n",
            "  0 - questions about the specific concepts,\n",
            "  1 - questions about strength and weakness of a specific product,\n",
            "  2 - questions about kinds of the product,\n",
            "  3 - requesting to get recommendation about products,\n",
            "  4 - questions about the solution of specific problem. \n",
            "\n",
            "  examples of types :\n",
            "  exapmles of questions for the types\n",
            "  0 type - [\"면진구조가 뭐야?\", \"폴리싱 타입이 뭐야?\"]\n",
            "  1 type - [\"철골 구조의 장점이 뭐야?\", \"포세린 타일의 단점이 뭐야?\"]\n",
            "  2 type - [\"화재 관련 마감재 종류가 뭐가 있어?\", \"내진 설계의 종류 좀 알려줘\"]\n",
            "  3 type - [\"방수 마갑재로 가장 널리 쓰이는 것은 뭐야?\"]\n",
            "  4 type - [\"겨울철 결로 방지를 하기 위해선 무엇을 해야해?\"]\n",
            "\n",
            "  expecations :\n",
            "\n",
            "  (1) question : 면진구조가 뭐야? / answer : 0\n",
            "  (2) question : 큐블럭의 단점이 뭐야? / answer : 1\n",
            "  (3) question : 도배풀의 종류 좀 알려줘 / answer : 2\n",
            "  (4) question : 벽지와 도료 중 어떤 것을 선택해야 하나요? / answer : 3\n",
            "  (5) question : 반점이 생긴지 1년 이내인 하자는 보수작업은 어떻게 해? / answer : 4\n",
            "\n",
            "  ###<ctrl63>\n",
            "\n",
            "  input :\n",
            "  \"차음재 종류는 뭐가 있어?\"\n",
            "\n",
            "  output :\n",
            "  ###\n",
            "  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\"\\\"열반사 단열재에 대해 설명해줘\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZK5xLIl4-Fz",
        "outputId": "505b46d2-86aa-406d-f37e-a64a145d59a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "  your role is text classifier. you are a helpful assistant. you should classify the input text into one of the following categories : [0, 1, 2, 3, 4, 5].\n",
            "\n",
            "  ###\n",
            "  instruction :\n",
            "  types of the text are 5. The texts are question statements\n",
            "  0 - questions about the specific concepts,\n",
            "  1 - questions about strength and weakness of a specific product,\n",
            "  2 - questions about kinds of the product,\n",
            "  3 - requesting to get recommendation about products,\n",
            "  4 - questions about the solution of specific problem. \n",
            "\n",
            "  examples of types :\n",
            "  exapmles of questions for the types\n",
            "  0 type - [\"면진구조가 뭐야?\", \"폴리싱 타입이 뭐야?\"]\n",
            "  1 type - [\"철골 구조의 장점이 뭐야?\", \"포세린 타일의 단점이 뭐야?\"]\n",
            "  2 type - [\"화재 관련 마감재 종류가 뭐가 있어?\", \"내진 설계의 종류 좀 알려줘\"]\n",
            "  3 type - [\"방수 마갑재로 가장 널리 쓰이는 것은 뭐야?\"]\n",
            "  4 type - [\"겨울철 결로 방지를 하기 위해선 무엇을 해야해?\"]\n",
            "\n",
            "  expecations :\n",
            "\n",
            "  (1) question : 면진구조가 뭐야? / answer : 0\n",
            "  (2) question : 큐블럭의 단점이 뭐야? / answer : 1\n",
            "  (3) question : 도배풀의 종류 좀 알려줘 / answer : 2\n",
            "  (4) question : 벽지와 도료 중 어떤 것을 선택해야 하나요? / answer : 3\n",
            "  (5) question : 반점이 생긴지 1년 이내인 하자는 보수작업은 어떻게 해? / answer : 4\n",
            "\n",
            "  ###<ctrl63>\n",
            "\n",
            "  input :\n",
            "  \"열반사 단열재에 대해 설명해줘\"\n",
            "\n",
            "  output :\n",
            "  ###\n",
            "  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.path.curdir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "u5dTuc3s6E-z",
        "outputId": "f449cd61-d869-467f-e763-fffcc25e6feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    }
  ]
}